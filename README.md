MSc Thesis Project - Learning to optimize neural networks

## Run

```bash
python main.py
```

### TODO
- [ ] Initial implementation of learning to optimize neural networks by gradient descent by gradient descent
    - [x] RNN optimizer
    - [x] Preprocessing gradients
    - [ ] Evaluating against other optimizers
- [ ] Adding different problems
    - [x] Simple classification of two gaussians
    - [x] MNIST 
    - [ ] Cifar-10 with convolutional networks
- [ ] Compare with standard optimizers
    - [x] SGD
    - [x] RMSProp
    - [ ] Adam
    - [ ] LBFGS
- [ ] Add RL optimizer - Policy Gradient
- [ ] Add parameter options
- [x] Save and load weights for meta-optimizer
